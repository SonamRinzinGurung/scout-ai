{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eba034a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_23904\\2874855951.py:3: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    'dataset/CollegeBasketballPlayers2009-2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4dc437dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61061, 66)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20912914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming attribute\n",
    "df = df.rename(columns={'Unnamed: 64': 'role_position'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "10878e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['player_name', 'team', 'conf', 'GP', 'Min_per', 'Ortg', 'usg', 'eFG',\n",
       "       'TS_per', 'ORB_per', 'DRB_per', 'AST_per', 'TO_per', 'FTM', 'FTA',\n",
       "       'FT_per', 'twoPM', 'twoPA', 'twoP_per', 'TPM', 'TPA', 'TP_per',\n",
       "       'blk_per', 'stl_per', 'ftr', 'yr', 'ht', 'num', 'porpag', 'adjoe',\n",
       "       'pfr', 'year', 'pid', 'type', 'Rec Rank', 'ast/tov', 'rimmade',\n",
       "       'rimmade+rimmiss', 'midmade', 'midmade+midmiss',\n",
       "       'rimmade/(rimmade+rimmiss)', 'midmade/(midmade+midmiss)', 'dunksmade',\n",
       "       'dunksmiss+dunksmade', 'dunksmade/(dunksmade+dunksmiss)', 'pick',\n",
       "       'drtg', 'adrtg', 'dporpag', 'stops', 'bpm', 'obpm', 'dbpm', 'gbpm',\n",
       "       'mp', 'ogbpm', 'dgbpm', 'oreb', 'dreb', 'treb', 'ast', 'stl', 'blk',\n",
       "       'pts', 'role_position', 'Unnamed: 65'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4777d98f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "role_position\n",
       "Wing G        12455\n",
       "PF/C          10220\n",
       "Combo G        8966\n",
       "C              8121\n",
       "Scoring PG     5837\n",
       "Wing F         4923\n",
       "Stretch 4      3191\n",
       "Pure PG        2664\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['role_position'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "072b56dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1435)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count number of picks that are not NaN\n",
    "df['pick'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28a61e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25719"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['player_name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f3b95c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61061, 36)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_cols = [\n",
    "    # ===== IDENTIFICATION =====\n",
    "    \"player_name\",  # For identification only\n",
    "\n",
    "    # ===== CONTEXT FEATURES =====\n",
    "    \"conf\",         # Conference (competition level)\n",
    "    \"yr\",           # Year in school (experience)\n",
    "    \"role_position\",  # Position played\n",
    "\n",
    "    # ===== PLAYING TIME & USAGE =====\n",
    "    \"Min_per\",      # Minutes per game (opportunity/trust)\n",
    "    \"usg\",          # Usage rate (how much offense runs through player)\n",
    "    \"GP\",           # Games played (availability)\n",
    "\n",
    "    # ===== EFFICIENCY METRICS (MOST IMPORTANT) =====\n",
    "    \"eFG\",          # Effective field goal % (shooting efficiency)\n",
    "    \"TS_per\",       # True shooting % (overall scoring efficiency)\n",
    "    \"FT_per\",       # Free throw % (skill indicator)\n",
    "    \"twoP_per\",     # Two-point shooting %\n",
    "    \"TP_per\",       # Three-point shooting %\n",
    "    \"ast/tov\",      # Assist-to-turnover ratio\n",
    "\n",
    "    # ===== ADVANCED METRICS =====\n",
    "    \"Ortg\",         # Offensive rating (points per 100 possessions)\n",
    "    \"bpm\",          # Box Plus/Minus (overall impact)\n",
    "    \"obpm\",         # Offensive Box Plus/Minus\n",
    "    \"dbpm\",         # Defensive Box Plus/Minus\n",
    "    \"adjoe\",        # Adjusted offensive efficiency\n",
    "    \"drtg\",         # Defensive rating\n",
    "    \"adrtg\",        # Adjusted defensive rating\n",
    "\n",
    "    # ===== PERCENTAGE STATS (SITUATIONAL) =====\n",
    "    \"ORB_per\",      # Offensive rebounding %\n",
    "    \"DRB_per\",      # Defensive rebounding %\n",
    "    \"AST_per\",      # Assist %\n",
    "    \"TO_per\",       # Turnover %\n",
    "    \"blk_per\",      # Block %\n",
    "    \"stl_per\",      # Steal %\n",
    "    \"ftr\",          # Free throw rate (ability to get to line)\n",
    "\n",
    "    # ===== SHOOTING BREAKDOWN =====\n",
    "    \"rimmade/(rimmade+rimmiss)\",           # Shooting at rim\n",
    "    \"midmade/(midmade+midmiss)\",           # Mid-range shooting\n",
    "    \"dunksmade/(dunksmade+dunksmiss)\",     # Dunk rate\n",
    "\n",
    "    # ===== COUNTING STATS (PRODUCTION) =====\n",
    "    \"pts\",          # Points per game\n",
    "    \"treb\",         # Total rebounds\n",
    "    \"ast\",          # Assists\n",
    "    \"stl\",          # Steals\n",
    "    \"blk\",          # Blocks\n",
    "\n",
    "    \"pick\"\n",
    "]\n",
    "\n",
    "\n",
    "df = df[[c for c in keep_cols if c in df.columns]]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b0f94485",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pick\"] = df[\"pick\"].fillna(\"Undrafted\")\n",
    "\n",
    "\n",
    "def categorize_pick(p):\n",
    "    if p == \"Undrafted\":\n",
    "        return \"Undrafted\"\n",
    "    try:\n",
    "        p = int(p)\n",
    "        if p <= 14:\n",
    "            return \"Lottery\"\n",
    "        elif p <= 30:\n",
    "            return \"1st Round\"\n",
    "        elif p <= 60:\n",
    "            return \"2nd Round\"\n",
    "        else:\n",
    "            return \"Undrafted\"  # safeguard\n",
    "    except:\n",
    "        return \"Undrafted\"\n",
    "\n",
    "\n",
    "df[\"pick_category\"] = df[\"pick\"].apply(categorize_pick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4da39f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pick_category\n",
       "Undrafted    59626\n",
       "2nd Round      812\n",
       "1st Round      361\n",
       "Lottery        262\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pick_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ffa90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add these before your current preprocessing\n",
    "def add_draft_specific_features(df):\n",
    "    df_enhanced = df.copy()\n",
    "\n",
    "    # 1. Elite performance indicators (top 10% thresholds)\n",
    "    df_enhanced['elite_scorer'] = (\n",
    "        df['pts'] > df['pts'].quantile(0.9)).astype(int)\n",
    "    df_enhanced['elite_efficiency'] = (\n",
    "        df['TS_per'] > df['TS_per'].quantile(0.9)).astype(int)\n",
    "    df_enhanced['elite_impact'] = (\n",
    "        df['bpm'] > df['bpm'].quantile(0.9)).astype(int)\n",
    "\n",
    "    # 2. Size + skill combination (NBA-ready indicators)\n",
    "    df_enhanced['versatile_big'] = (\n",
    "        (df['role_position'].isin(['PF', 'C'])) &\n",
    "        (df['TP_per'] > 0.3)  # Big who can shoot 3s\n",
    "    ).astype(int)\n",
    "\n",
    "    # 3. Usage + efficiency (can handle big role efficiently)\n",
    "    df_enhanced['high_usage_efficient'] = (\n",
    "        (df['usg'] > df['usg'].quantile(0.8)) &\n",
    "        (df['TS_per'] > 0.55)\n",
    "    ).astype(int)\n",
    "\n",
    "    # 4. Power conference performance\n",
    "    power_confs = ['ACC', 'Big 12', 'Big Ten', 'SEC', 'Pac-12', 'Big East']\n",
    "    df_enhanced['power_conf_star'] = (\n",
    "        (df['conf'].isin(power_confs)) &\n",
    "        (df['pts'] > 15)  # Star in power conference\n",
    "    ).astype(int)\n",
    "\n",
    "    return df_enhanced\n",
    "\n",
    "\n",
    "# Apply before train-test split\n",
    "df_enhanced = add_draft_specific_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4f05dc36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61061, 43)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_enhanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6793bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Preprocessing pipeline ready. X_train shape: (48848, 40)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Separate target\n",
    "X = df_enhanced.drop(columns=[\"pick\", \"player_name\",\"pick_category\"])  # features\n",
    "y = df_enhanced[\"pick_category\"]  # target\n",
    "\n",
    "# Final pipeline (ready for any model)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Preprocessing pipeline ready. X_train shape:\", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1e29d818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 2. Preprocessing\n",
    "# -----------------------\n",
    "numeric_features = X.select_dtypes(\n",
    "    include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "categorical_features = [ \"conf\", \"yr\", \"role_position\"]\n",
    "\n",
    "# Imputers\n",
    "num_imputer = SimpleImputer(strategy=\"median\")\n",
    "cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "\n",
    "# Fit imputers\n",
    "X_train_num = num_imputer.fit_transform(X_train[numeric_features])\n",
    "X_test_num = num_imputer.transform(X_test[numeric_features])\n",
    "\n",
    "X_train_cat = cat_imputer.fit_transform(X_train[categorical_features])\n",
    "X_test_cat = cat_imputer.transform(X_test[categorical_features])\n",
    "\n",
    "# Scale numeric\n",
    "scaler = StandardScaler()\n",
    "X_train_num = scaler.fit_transform(X_train_num)\n",
    "X_test_num = scaler.transform(X_test_num)\n",
    "\n",
    "# Encode categorical\n",
    "encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "X_train_cat = encoder.fit_transform(X_train_cat)\n",
    "X_test_cat = encoder.transform(X_test_cat)\n",
    "\n",
    "# Concatenate processed features\n",
    "X_train_processed = np.hstack([X_train_num, X_train_cat])\n",
    "X_test_processed = np.hstack([X_test_num, X_test_cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cbbd8064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\Documents\\Side Missions\\scout-ai\\backend\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [17:25:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"class_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Stage 1 Report (Drafted vs Undrafted) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     11905\n",
      "           1       0.57      0.56      0.56       308\n",
      "\n",
      "    accuracy                           0.98     12213\n",
      "   macro avg       0.78      0.77      0.78     12213\n",
      "weighted avg       0.98      0.98      0.98     12213\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "# -----------------------\n",
    "# 3. Stage 1 Labels (Drafted vs Undrafted)\n",
    "# -----------------------\n",
    "y_stage1 = (y_train != \"Undrafted\").astype(int)   # 0 = Undrafted, 1 = Drafted\n",
    "y_stage1_test = (y_test != \"Undrafted\").astype(int)\n",
    "\n",
    "# -----------------------\n",
    "# 4. Handle Imbalance (SMOTE)\n",
    "# -----------------------\n",
    "smote = SMOTE(random_state=42, sampling_strategy=0.8, k_neighbors=3)\n",
    "X_train_stage1, y_stage1_bal = smote.fit_resample(X_train_processed, y_stage1)\n",
    "\n",
    "sample_weights = compute_sample_weight('balanced', y_stage1_bal)\n",
    "\n",
    "# -----------------------\n",
    "# 5. Train Stage 1 Classifier\n",
    "# -----------------------\n",
    "scale_pos_weight = (len(y_stage1) - sum(y_stage1)) / sum(y_stage1)\n",
    "\n",
    "xgb_stage1 = xgb.XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    class_weight='balanced',\n",
    "    # scale_pos_weight=3,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=200,\n",
    "    # scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42,\n",
    "    use_label_encoder=False\n",
    ")\n",
    "\n",
    "xgb_stage1.fit(X_train_stage1, y_stage1_bal, sample_weight=sample_weights)\n",
    "y_stage1_pred = xgb_stage1.predict(X_test_processed)\n",
    "\n",
    "print(\"\\n=== Stage 1 Report (Drafted vs Undrafted) ===\")\n",
    "print(classification_report(y_stage1_test, y_stage1_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b7688fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ ENSEMBLE Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     11905\n",
      "           1       0.53      0.63      0.57       308\n",
      "\n",
      "    accuracy                           0.98     12213\n",
      "   macro avg       0.76      0.81      0.78     12213\n",
      "weighted avg       0.98      0.98      0.98     12213\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\Documents\\Side Missions\\scout-ai\\backend\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# ENSEMBLE OF BEST MODELS\n",
    "# =============================================\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create ensemble of top performers\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('catboost', CatBoostClassifier(class_weights=[1, 8], verbose=False)),\n",
    "        ('lightgbm', LGBMClassifier(class_weight='balanced', verbose=-1)),\n",
    "        ('rf', RandomForestClassifier(class_weight='balanced', n_jobs=-1))\n",
    "    ],\n",
    "    voting='soft'  # Use probability averaging\n",
    ")\n",
    "\n",
    "ensemble.fit(X_train_stage1, y_stage1_bal)\n",
    "y_ensemble_pred = ensemble.predict(X_test_processed)\n",
    "\n",
    "print(\"\\nðŸš€ ENSEMBLE Results:\")\n",
    "print(classification_report(y_stage1_test, y_ensemble_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2dad8537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model saved: models/nba_draft_ensemble_model_20250925.pkl\n",
      "âœ… Preprocessors saved: models/nba_draft_preprocessors_20250925.pkl\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# SAVE MODEL AND PREPROCESSORS FOR DEPLOYMENT\n",
    "# =============================================\n",
    "import pickle\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "# Create models directory\n",
    "import os\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Save the trained ensemble model\n",
    "model_filename = f'models/nba_draft_ensemble_model_{datetime.now().strftime(\"%Y%m%d\")}.pkl'\n",
    "joblib.dump(ensemble, model_filename)\n",
    "\n",
    "# Save all preprocessors (CRITICAL for production)\n",
    "preprocessors = {\n",
    "    'num_imputer': num_imputer,\n",
    "    'cat_imputer': cat_imputer,\n",
    "    'scaler': scaler,\n",
    "    'encoder': encoder,\n",
    "    'numeric_features': numeric_features,\n",
    "    'categorical_features': categorical_features,\n",
    "    'feature_columns': list(X.columns),  # Original feature names\n",
    "    'smote': smote  # In case you need to understand the training process\n",
    "}\n",
    "\n",
    "preprocessor_filename = f'models/nba_draft_preprocessors_{datetime.now().strftime(\"%Y%m%d\")}.pkl'\n",
    "joblib.dump(preprocessors, preprocessor_filename)\n",
    "\n",
    "print(f\"âœ… Model saved: {model_filename}\")\n",
    "print(f\"âœ… Preprocessors saved: {preprocessor_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9628a81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Production predictor class saved!\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# PRODUCTION-READY NBA DRAFT PREDICTOR CLASS\n",
    "# =============================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from typing import Dict, List, Union\n",
    "\n",
    "\n",
    "class NBADraftPredictor:\n",
    "    \"\"\"\n",
    "    NBA Draft Prospect Predictor\n",
    "    Predicts if a college basketball player will be drafted to NBA\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_path: str, preprocessor_path: str):\n",
    "        \"\"\"Load trained model and preprocessors\"\"\"\n",
    "        self.model = joblib.load(model_path)\n",
    "        self.preprocessors = joblib.load(preprocessor_path)\n",
    "\n",
    "        # Extract preprocessors\n",
    "        self.num_imputer = self.preprocessors['num_imputer']\n",
    "        self.cat_imputer = self.preprocessors['cat_imputer']\n",
    "        self.scaler = self.preprocessors['scaler']\n",
    "        self.encoder = self.preprocessors['encoder']\n",
    "        self.numeric_features = self.preprocessors['numeric_features']\n",
    "        self.categorical_features = self.preprocessors['categorical_features']\n",
    "        self.feature_columns = self.preprocessors['feature_columns']\n",
    "\n",
    "        print(\"âœ… NBA Draft Predictor loaded successfully!\")\n",
    "        print(f\"   Model: {type(self.model).__name__}\")\n",
    "        print(f\"   Expected features: {len(self.feature_columns)}\")\n",
    "\n",
    "    def add_draft_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Add engineered features used during training\"\"\"\n",
    "        df_enhanced = df.copy()\n",
    "\n",
    "        # Elite performance indicators (top 10% thresholds from training data)\n",
    "        df_enhanced['elite_scorer'] = (df['pts'] > 20.0).astype(\n",
    "            int)  # Approximate threshold\n",
    "        df_enhanced['elite_efficiency'] = (df['TS_per'] > 0.65).astype(int)\n",
    "        df_enhanced['elite_impact'] = (df['bpm'] > 8.0).astype(int)\n",
    "\n",
    "        # Size + skill combination\n",
    "        df_enhanced['versatile_big'] = (\n",
    "            (df['role_position'].isin(['PF', 'C'])) &\n",
    "            (df['TP_per'] > 0.3)\n",
    "        ).astype(int)\n",
    "\n",
    "        # Usage + efficiency\n",
    "        df_enhanced['high_usage_efficient'] = (\n",
    "            (df['usg'] > 25.0) &  # Approximate 80th percentile\n",
    "            (df['TS_per'] > 0.55)\n",
    "        ).astype(int)\n",
    "\n",
    "        # Power conference performance\n",
    "        power_confs = ['ACC', 'Big 12', 'Big Ten', 'SEC', 'Pac-12', 'Big East']\n",
    "        df_enhanced['power_conf_star'] = (\n",
    "            (df['conf'].isin(power_confs)) &\n",
    "            (df['pts'] > 15)\n",
    "        ).astype(int)\n",
    "\n",
    "        return df_enhanced\n",
    "\n",
    "    def preprocess_data(self, df: pd.DataFrame) -> np.ndarray:\n",
    "        \"\"\"Preprocess input data exactly like training data\"\"\"\n",
    "\n",
    "        # Add engineered features\n",
    "        df_processed = self.add_draft_features(df)\n",
    "\n",
    "        # Ensure all required columns are present\n",
    "        missing_cols = set(self.feature_columns) - set(df_processed.columns)\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "\n",
    "        # Select only the features used in training\n",
    "        df_processed = df_processed[self.feature_columns]\n",
    "\n",
    "        # Separate numeric and categorical\n",
    "        df_num = df_processed[self.numeric_features]\n",
    "        df_cat = df_processed[self.categorical_features]\n",
    "\n",
    "        # Apply same preprocessing as training\n",
    "        X_num = self.num_imputer.transform(df_num)\n",
    "        X_cat = self.cat_imputer.transform(df_cat)\n",
    "\n",
    "        # Scale and encode\n",
    "        X_num = self.scaler.transform(X_num)\n",
    "        X_cat = self.encoder.transform(X_cat)\n",
    "\n",
    "        # Combine features\n",
    "        X_processed = np.hstack([X_num, X_cat])\n",
    "\n",
    "        return X_processed\n",
    "\n",
    "    def predict_draft_probability(self, player_data: Union[Dict, pd.DataFrame]) -> Dict:\n",
    "        \"\"\"\n",
    "        Predict draft probability for a player or players\n",
    "\n",
    "        Args:\n",
    "            player_data: Dict with player stats or DataFrame with multiple players\n",
    "\n",
    "        Returns:\n",
    "            Dict with prediction results\n",
    "        \"\"\"\n",
    "        # Convert dict to DataFrame if needed\n",
    "        if isinstance(player_data, dict):\n",
    "            df = pd.DataFrame([player_data])\n",
    "            single_player = True\n",
    "        else:\n",
    "            df = player_data.copy()\n",
    "            single_player = False\n",
    "\n",
    "        try:\n",
    "            # Preprocess data\n",
    "            X_processed = self.preprocess_data(df)\n",
    "\n",
    "            # Get predictions and probabilities\n",
    "            predictions = self.model.predict(X_processed)\n",
    "            probabilities = self.model.predict_proba(\n",
    "                X_processed)[:, 1]  # Probability of being drafted\n",
    "\n",
    "            # Prepare results\n",
    "            results = {\n",
    "                'predictions': predictions.tolist(),\n",
    "                'draft_probabilities': probabilities.tolist(),\n",
    "                'draft_decisions': ['Drafted' if pred == 1 else 'Undrafted' for pred in predictions]\n",
    "            }\n",
    "\n",
    "            # Add player names if available\n",
    "            if 'player_name' in df.columns:\n",
    "                results['player_names'] = df['player_name'].tolist()\n",
    "\n",
    "            # If single player, return simplified format\n",
    "            if single_player:\n",
    "                return {\n",
    "                    'player_name': df['player_name'].iloc[0] if 'player_name' in df.columns else 'Unknown',\n",
    "                    'draft_probability': float(probabilities[0]),\n",
    "                    'prediction': 'Drafted' if predictions[0] == 1 else 'Undrafted',\n",
    "                    'confidence': 'High' if probabilities[0] > 0.7 or probabilities[0] < 0.3 else 'Medium'\n",
    "                }\n",
    "\n",
    "            return results\n",
    "\n",
    "        except Exception as e:\n",
    "            return {'error': f\"Prediction failed: {str(e)}\"}\n",
    "\n",
    "\n",
    "# Save the predictor class\n",
    "predictor_code = '''\n",
    "# Copy the NBADraftPredictor class code here for external use\n",
    "'''\n",
    "\n",
    "with open('models/nba_draft_predictor.py', 'w') as f:\n",
    "    f.write(predictor_code)\n",
    "\n",
    "print(\"âœ… Production predictor class saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "91e42107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… NBA Draft Predictor loaded successfully!\n",
      "   Model: VotingClassifier\n",
      "   Expected features: 40\n",
      "\n",
      "ðŸ€ PREDICTION RESULT:\n",
      "   Player: Test Player\n",
      "   Draft Probability: 54.3%\n",
      "   Prediction: Drafted\n",
      "   Confidence: Medium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\Documents\\Side Missions\\scout-ai\\backend\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\ASUS\\Documents\\Side Missions\\scout-ai\\backend\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import models.nba_draft_predictor as ndp\n",
    "\n",
    "predictor = ndp.NBADraftPredictor(\n",
    "    \"models/nba_draft_ensemble_model_20250925.pkl\", \"models/nba_draft_preprocessors_20250925.pkl\")\n",
    "\n",
    "\n",
    "# Test with a single player (example data)\n",
    "test_player = {\n",
    "    'player_name': 'Test Player',\n",
    "    'conf': 'ACC',\n",
    "    'yr': 'Jr',\n",
    "    'role_position': 'SF',\n",
    "    'Min_per': 32.5,\n",
    "    'usg': 28.2,\n",
    "    'GP': 30,\n",
    "    'eFG': 0.58,\n",
    "    'TS_per': 0.62,\n",
    "    'FT_per': 0.85,\n",
    "    'twoP_per': 0.55,\n",
    "    'TP_per': 0.38,\n",
    "    'ast/tov': 1.8,\n",
    "    'Ortg': 115.0,\n",
    "    'bpm': 7.2,\n",
    "    'obpm': 5.8,\n",
    "    'dbpm': 1.4,\n",
    "    'adjoe': 118.0,\n",
    "    'drtg': 98.0,\n",
    "    'adrtg': 95.0,\n",
    "    'ORB_per': 8.5,\n",
    "    'DRB_per': 18.2,\n",
    "    'AST_per': 22.0,\n",
    "    'TO_per': 12.5,\n",
    "    'blk_per': 3.2,\n",
    "    'stl_per': 2.8,\n",
    "    'ftr': 0.42,\n",
    "    'rimmade/(rimmade+rimmiss)': 0.68,\n",
    "    'midmade/(midmade+midmiss)': 0.45,\n",
    "    'dunksmade/(dunksmade+dunksmiss)': 0.85,\n",
    "    'pts': 18.5,\n",
    "    'treb': 8.2,\n",
    "    'ast': 4.1,\n",
    "    'stl': 1.2,\n",
    "    'blk': 1.8\n",
    "}\n",
    "\n",
    "# Make prediction\n",
    "result = predictor.predict_draft_probability(test_player)\n",
    "print(\"\\nðŸ€ PREDICTION RESULT:\")\n",
    "print(f\"   Player: {result['player_name']}\")\n",
    "print(f\"   Draft Probability: {result['draft_probability']:.1%}\")\n",
    "print(f\"   Prediction: {result['prediction']}\")\n",
    "print(f\"   Confidence: {result['confidence']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
